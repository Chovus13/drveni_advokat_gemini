TehniÄki Arhitektonski Nacrt: Lokalni Pravni AI Agent 'Drveni Advokat'


I. Temeljna Arhitektura: Nacrt za 'Drvenog Advokata'

Ovaj dokument predstavlja sveobuhvatni tehniÄki nacrt za razvoj lokalnog, privatnog AI pravnog agenta pod nazivom 'Drveni advokat'. Cilj projekta je stvoriti trajno nasleÄ‘e transformacijom obimnog liÄnog arhiva pravnih predmeta u inteligentni sistem sposoban za rezonovanje i uÄenje. Arhitektura je osmiÅ¡ljena da funkcioniÅ¡e u potpunosti lokalno, bez zavisnosti od eksternih cloud servisa, Äime se garantuje apsolutna privatnost i kontrola nad podacima.

1.1. Pregled Sistema i Osnovna Filozofija

Osnovna filozofija projekta 'Drveni advokat' nije stvaranje joÅ¡ jednog Äet-bota za pitanja i odgovore, veÄ‡ implementacija sofisticiranog "Äovek-u-petlji" (man-in-the-loop) sistema. U ovom modelu, ekspertiza penzionisanog advokata nije samo poÄetni izvor podataka, veÄ‡ kontinuirani, aktivni signal za obuku. 'Drveni advokat' je koncipiran ne kao statiÄki repozitorijum znanja, veÄ‡ kao digitalni pripravnik dizajniran da uÄi direktno od svog mentora. Sistem je strukturiran oko Äetiri fundamentalna, meÄ‘usobno povezana modula koji zajedno Äine ciklus uÄenja i usavrÅ¡avanja.
Cevovod za Unos Podataka (Data Ingestion Pipeline): Industrijski robustan proces zaduÅ¾en za konverziju, parsiranje i strukturiranje korpusa od 200 GB pravnih predmeta iz zastarelog .doc formata. Ovaj modul je temelj na kojem se gradi celokupno znanje sistema.
Jezgro za Rezonovanje zasnovano na RAG-u (RAG Reasoning Core): Primarni mehanizam za odgovaranje na upite, izgraÄ‘en koriÅ¡Ä‡enjem LangChain okvira, lokalnog velikog jeziÄkog modela (LLM) i vektorske baze podataka. Ovaj modul pruÅ¾a agentu sposobnost da koristi steÄeno znanje.
Interaktivni Interfejs za Korekciju (Interactive Correction Interface): KorisniÄki interfejs zasnovan na Streamlit-u, putem kojeg mentor (advokat) interaguje sa agentom, ocenjuje njegove odgovore i pruÅ¾a precizne korekcije. Ovo je kljuÄni mehanizam za prikupljanje i digitalizaciju ekspertize.
Petlja za Fino PodeÅ¡avanje (PEFT/LoRA Fine-Tuning Loop): Automatizovani pozadinski proces koji pretvara povratne informacije mentora u strukturirani set podataka za obuku i periodiÄno usavrÅ¡ava LLM. Ovaj modul omoguÄ‡ava agentu da uÄi kako da rezonuje, a ne samo Å¡ta da zna.
Ovakav pristup osigurava da sistem evoluira. PoÄetna faza se oslanja na pretragu i sintezu postojeÄ‡ih informacija (Retrieval-Augmented Generation - RAG), dok svaka interakcija i korekcija postepeno transformiÅ¡e model, ugraÄ‘ujuÄ‡i u njega suptilne nijanse pravnog rezonovanja koje se ne mogu naÄ‡i u sirovom tekstu.

1.2. Arhitektonski Dijagram

Tok podataka i kontrolnih signala unutar sistema 'Drveni advokat' je kljuÄan za razumevanje njegove dinamike. Dijagram ispod vizuelno predstavlja celokupan radni proces, od postavljanja upita do aÅ¾uriranja modela na osnovu ekspertske korekcije.
Tok Interakcije i Rezonovanja:
Korisnik (advokat) unosi upit (User Query) putem Streamlit UI.
Streamlit aplikacija prosleÄ‘uje upit LangChain RAG Agentu.
Agent koristi Embedding Model da pretvori upit u vektorsku reprezentaciju.
Agent pretraÅ¾uje vektorsku bazu Qdrant za relevantne dokumente (fragmente predmeta).
Preuzeti dokumenti i originalni upit se formatiraju u prompt i Å¡alju lokalnom LLM (Ollama).
LLM generiÅ¡e odgovor (LLM Response) na osnovu pruÅ¾enog konteksta.
Odgovor se prikazuje korisniku u Streamlit UI.
Tok UÄenja i Korekcije:
Korisnik ocenjuje odgovor i unosi ispravku (Expert Feedback) u Streamlit UI.
Interfejs beleÅ¾i kompletan kontekst interakcije (upit, istorijat, originalni odgovor, ispravka) u Feedback Log (JSONL) datoteku.
PeriodiÄno, Fine-Tuning Script se pokreÄ‡e, obraÄ‘ujuÄ‡i Feedback Log.
Skripta generiÅ¡e set podataka za obuku i koristi ga za fino podeÅ¡avanje LLM-a putem LoRA tehnike, stvarajuÄ‡i novi LoRA Adapter.
Prilikom sledeÄ‡eg pokretanja, LangChain RAG Agent uÄitava osnovni Local LLM i primenjuje na njega najnoviji LoRA Adapter, Äime agent postaje "pametniji".
Ovaj dvostruki ciklusâ€”jedan za rezonovanje u realnom vremenu i drugi za periodiÄno uÄenjeâ€”Äini srÅ¾ arhitekture i omoguÄ‡ava sistemu da se kontinuirano usavrÅ¡ava.

1.3. KljuÄne TehniÄke Odluke i ObrazloÅ¾enja

Svaka komponenta u arhitekturi je paÅ¾ljivo odabrana da ispuni specifiÄne zahteve projekta, sa posebnim naglaskom na lokalno izvrÅ¡avanje, performanse i sposobnost uÄenja.
Mandat "Lokalno-Prvo" (Local-First): Primarni cilj projekta je potpuna privatnost i autonomija. Ova odluka momentalno iskljuÄuje sve cloud-bazirane API servise za konverziju dokumenata 1, LLM-ove ili baze podataka. Celokupan sistem, od obrade podataka do inferencije modela, mora se izvrÅ¡avati na lokalnom hardveru.
Odabir Velikog JeziÄkog Modela (LLM): Umesto koriÅ¡Ä‡enja generiÄkog modela kao Å¡to je mistralai/Mistral-7B-v0.1, projekat Ä‡e zapoÄeti sa modelom koji je veÄ‡ proÅ¡ao fazu kontinuiranog pre-treninga na srpskom, odnosno BCS (bosanski, hrvatski, srpski) jezicima. Dva primarna kandidata su gordicaleksa/YugoGPT 4 i
iskonai/prodigy-sm-base-v0.1.5 Ovi modeli, zasnovani na Mistral 7B arhitekturi, pruÅ¾aju znaÄajnu prednost u razumevanju jeziÄkih i pravnih nijansi specifiÄnih za domaÄ‡i kontekst, smanjujuÄ‡i potrebu za masivnim poÄetnim finim podeÅ¡avanjem.
Odabir Vektorske Baze Podataka: Izbor pada na Qdrant umesto na alternative poput ChromaDB. Razlog je viÅ¡estruk: Qdrant nudi superiorne performanse, dokazanu skalabilnost i, Å¡to je najvaÅ¾nije za ovaj projekat, napredne moguÄ‡nosti filtriranja po metapodacima.6 Pravni upiti Äesto zahtevaju kombinaciju semantiÄke pretrage ("sluÄajevi sliÄni ovome") i striktnog filtriranja ("gde je sudija bio X" ili "posle 2010. godine"). Qdrant-ova sposobnost da efikasno izvrÅ¡i pre-filtriranje pretrage na osnovu indeksiranih metapodataka je kljuÄna funkcionalnost.9
Okviri za Razvoj (Development Frameworks): LangChain Ä‡e sluÅ¾iti kao orkestrator za RAG cevovod, omoguÄ‡avajuÄ‡i modularno i jasno definisanje logike pretrage i generisanja.11 Za interaktivni interfejs,
Streamlit je odabran zbog svoje jednostavnosti i brzine razvoja, Å¡to omoguÄ‡ava fokus na funkcionalnost petlje za povratne informacije bez potrebe za kompleksnim web developmentom.14
Ove odluke zajedno formiraju koherentnu i robusnu osnovu, optimizovanu za specifiÄne ciljeve projekta 'Drveni advokat', gde je interaktivno uÄenje i usavrÅ¡avanje modela centralni, a ne sporedni, element sistema.

II. Faza 1: Kovanje Jezgra Znanja - Unos 200 GB Pravnih Precedenata

Ovo je najkritiÄnija i radno najintenzivnija faza projekta. Kvalitet celokupnog sistema zavisi od uspeÅ¡ne, pouzdane i potpune obrade arhive od 200 GB .doc datoteka. Neuspeh u ovoj fazi predstavlja neuspeh celog projekta. Stoga, pristup mora biti metodiÄan i robustan, tretirajuÄ‡i ovaj korak kao industrijski ETL (Extract, Transform, Load) proces, a ne kao jednostavno Äitanje datoteka.

2.1. Izazov Konverzije .doc Formata: Strategija i Implementacija

Problem: Stari .doc format je binarni, vlasniÄki format Microsoft Worda (pre 2007). Direktno parsiranje ovog formata u Python-u je izuzetno nepouzdano. Biblioteke kao Å¡to je python-docx eksplicitno podrÅ¾avaju samo moderni, na XML-u zasnovan .docx format.16 Alati poput
textract Äesto deluju kao omotaÄi oko eksternih komandnih alata kao Å¡to je antiword 19, Äija podrÅ¡ka za kompleksno formatiranje, tabele, i specifiÄne verzije
.doc formata moÅ¾e biti ograniÄena.21 Za korpus ove veliÄine i vaÅ¾nosti, potreban je pouzdaniji metod.
Odabrana Strategija: Orkestracija putem Komandne Linije: Najrobusniji pristup je kreiranje Python skripte koja koristi subprocess modul za pozivanje moÄ‡nog, eksternog alata za konverziju za svaku .doc datoteku. Ovo razdvaja logiku naÅ¡eg programa od kompleksnosti samog procesa konverzije.
Odabir Alata:
Primarna Preporuka: LibreOffice (soffice): LibreOffice je poznat po svojoj izvanrednoj kompatibilnosti sa Å¡irokim spektrom starih formata dokumenata. Njegov interfejs komandne linije je izuzetno moÄ‡an i idealan za skriptovanje masovnih konverzija.22 MoÅ¾e se pokrenuti u
--headless reÅ¾imu, Å¡to znaÄi da ne zahteva grafiÄki interfejs i savrÅ¡en je za automatizovane, pozadinske zadatke.25 Ovo je najpouzdaniji metod za ovaj projekat.
Alternativa (Samo za Windows): pywin32: Ova biblioteka omoguÄ‡ava automatizaciju same Microsoft Word aplikacije putem COM (Component Object Model) interfejsa.28 Iako je ovo validan pristup, on je inherentno krhkiji za masovnu obradu. Zahteva punu instalaciju MS Word-a, podloÅ¾an je greÅ¡kama koje aplikacija moÅ¾e prikazati (npr. iskaÄuÄ‡i prozori), i generalno je sporiji i manje stabilan za dugotrajne, ne-nadzirane procese.30
pywin32 Ä‡e biti razmatran kao rezervna opcija, ali se soffice preporuÄuje kao primarno reÅ¡enje.
Skripta za Konverziju (convert_corpus.py):
Ova skripta mora biti dizajnirana sa naglaskom na robusnost, logovanje i moguÄ‡nost nastavka prekinutog procesa.
Rekurzivno Skeniranje: Koristiti os.walk za prolazak kroz celokupnu strukturu direktorijuma od 200 GB.
Konstrukcija Komande: Za svaku pronaÄ‘enu .doc datoteku, dinamiÄki konstruisati komandu za soffice, na primer: soffice --headless --convert-to docx --outdir "<ciljni_direktorijum>" "<izvorna_datoteka.doc>". Ciljni direktorijum treba da preslikava strukturu izvornog direktorijuma kako bi se saÄuvala organizacija.
IzvrÅ¡avanje i Logovanje: IzvrÅ¡iti komandu koristeÄ‡i subprocess.run. Neophodno je uhvatiti standardni izlaz (stdout) i standardni izlaz za greÅ¡ke (stderr). Svaki pokuÅ¡aj konverzije, bilo da je uspeÅ¡an ili neuspeÅ¡an, mora biti zabeleÅ¾en u datoteku conversion_log.txt. U sluÄaju greÅ¡ke, kompletan stderr mora biti saÄuvan radi kasnije analize.
MoguÄ‡nost Nastavka (Resumability): Pre pokuÅ¡aja konverzije, skripta mora proveriti da li ciljna .docx datoteka veÄ‡ postoji. Ako postoji, preskoÄiti konverziju i zabeleÅ¾iti to u log. Ovo je kljuÄno jer proces konverzije moÅ¾e trajati danima i verovatno Ä‡e biti prekidan. Bez ove funkcionalnosti, svaki prekid bi zahtevao poÄetak od nule.

2.2. Ekstrakcija Teksta i Metapodataka iz .docx Formata

Nakon uspeÅ¡ne konverzije celokupnog korpusa u .docx format, sledi faza ekstrakcije informacija.
Odabir Parsera: Biblioteka python-docx je industrijski standard za rad sa .docx datotekama u Python-u.16 Ona pruÅ¾a strukturiran pristup sadrÅ¾aju dokumenta, omoguÄ‡avajuÄ‡i iteraciju kroz paragrafe, tabele, sekcije i druge elemente.
Ekstrakcija Metapodataka: Metapodaci su jednako vaÅ¾ni kao i sam tekstualni sadrÅ¾aj, jer omoguÄ‡avaju kasnije precizno filtriranje. Ekstrakcija Ä‡e se vrÅ¡iti na dva nivoa:
UgraÄ‘eni Metapodaci (Core Properties): KoristeÄ‡i doc.core_properties objekat iz python-docx, ekstrahovaÄ‡e se standardna polja kao Å¡to su autor (author), datum kreiranja (created), datum izmene (modified), naslov (title) i komentari (comments).33
Izvedeni Metapodaci (Content-Derived Metadata): Najvredniji metapodaci se nalaze unutar samog teksta. KoristiÄ‡e se modul za regularne izraze (re) za parsiranje teksta i pronalaÅ¾enje kljuÄnih, strukturiranih informacija. Obrasci Ä‡e biti definisani za pronalaÅ¾enje specifiÄnih pravnih termina kao Å¡to su: Broj predmeta:, Sudija:, TuÅ¾ilac:, TuÅ¾eni:, Sud:, Datum presude:, itd. Ovi podaci Ä‡e biti ekstrahovani i saÄuvani kao strukturirana polja.
Rukovanje Kodiranjem Znakova (Character Encoding): S obzirom da korpus sadrÅ¾i srpske dijakritiÄke znakove (Å¡, Ä‘, Ä, Ä‡, Å¾), sve operacije Äitanja i pisanja datoteka moraju eksplicitno koristiti encoding='utf-8' kako bi se izbegla korupcija podataka.35 SreÄ‡om,
.docx format je zasnovan na XML-u, koji je inherentno UTF-8, tako da python-docx biblioteka ovo reÅ¡ava transparentno.38

2.3. ÄŒiÅ¡Ä‡enje, Strukturiranje i Segmentacija Podataka

Sirovi tekst iz dokumenata nije pogodan za direktnu upotrebu u RAG sistemu. Potrebna je paÅ¾ljiva priprema.
ÄŒiÅ¡Ä‡enje Podataka (Data Cleaning): Pravni dokumenti sadrÅ¾e veliku koliÄinu repetitivnog, "boilerplate" tekstaâ€”zaglavlja, podnoÅ¾ja, peÄati, standardne pravne formulacije, itd. Potrebno je razviti funkcije koje Ä‡e identifikovati i ukloniti ove delove teksta. Uklanjanje ovog "Å¡uma" je kljuÄno za poboljÅ¡anje odnosa signala i Å¡uma u vektorskoj pretrazi, osiguravajuÄ‡i da se pretraga fokusira na suÅ¡tinski sadrÅ¾aj predmeta.
Strukturiranje za Unos: Svaki originalni dokument Ä‡e biti transformisan u jedan ili viÅ¡e JSON objekata koji sadrÅ¾e sve relevantne informacije. Ova struktura Ä‡e biti osnova za unos u vektorsku bazu.

JSON


{
  "source_file": "putanja/do/originalnog.doc",
  "case_id": "P-123-2005",
  "full_text": "Kompletan oÄiÅ¡Ä‡en tekst dokumenta...",
  "metadata": {
    "judge": "Marko MarkoviÄ‡",
    "plaintiff": "Petar PetroviÄ‡",
    "defendant": "Jovan JovanoviÄ‡",
    "decision_date": "2006-11-15",
    "court": "Osnovni sud u Beogradu",
    "document_type": "Presuda"
  }
}


Strategija Segmentacije (Chunking): Veliki jeziÄki modeli imaju ograniÄen kontekstni prozor. Stoga, dugi dokumenti moraju biti podeljeni na manje, semantiÄki koherentne delove (chunks).
Metod: KoristiÄ‡e se RecursiveCharacterTextSplitter iz LangChain biblioteke. MeÄ‘utim, umesto generiÄkih separatora, biÄ‡e konfigurisani da koriste separatore koji imaju smisla u pravnom kontekstu, kao Å¡to su dvostruki prelom reda (\n\n), reference na Älanove zakona (ÄŒlan...), ili podnaslovi unutar dokumenta.
NasleÄ‘ivanje Metapodataka: Svaki generisani segment (chunk) Ä‡e naslediti sve metapodatke od svog roditeljskog dokumenta. Ovo je od suÅ¡tinskog znaÄaja, jer omoguÄ‡ava da se prilikom pretrage vrati mali, relevantan segment teksta, ali da se uz njega dobije i kompletan kontekst (broj predmeta, sudija, itd.) iz kojeg potiÄe.
Ova temeljna i paÅ¾ljiva priprema podataka osigurava da Ä‡e znanje uneto u 'Drvenog advokata' biti Äisto, strukturirano i maksimalno iskoristivo za kasnije faze rezonovanja i uÄenja.

III. Faza 2: Izgradnja Mehanizma za Rezonovanje - RAG Sistem za Pravnu Analizu

Sa pripremljenom i strukturiranom bazom znanja, sledeÄ‡i korak je izgradnja jezgra sistema koje Ä‡e omoguÄ‡iti 'Drvenom advokatu' da rezonuje i odgovara na upite. Ova faza se fokusira na postavljanje lokalne AI infrastrukture i orkestraciju toka informacija neophodnog za napredno pretraÅ¾ivanje i generisanje odgovora.

3.1. Postavljanje Lokalnog LLM-a i OkruÅ¾enja

Ollama za Serviranje Modela: Za upravljanje i serviranje velikog jeziÄkog modela (LLM) na lokalnoj maÅ¡ini, koristiÄ‡e se Ollama.39 Ollama pojednostavljuje proces preuzimanja, pokretanja i interakcije sa LLM-ovima, pruÅ¾ajuÄ‡i standardizovan API endpoint (
http://localhost:11434) na koji se LangChain moÅ¾e lako povezati.41 Ovo apstrahuje kompleksnost direktnog upravljanja modelom, uÄitavanjem na GPU i konfiguracijom inferentnog servera.
Odabir Modela: Kao Å¡to je definisano u temeljnoj arhitekturi, polazna taÄka neÄ‡e biti generiÄki model. KoristiÄ‡e se model koji je veÄ‡ proÅ¡ao pre-trening na srpskom jeziku, Äime se osigurava bolje fundamentalno razumevanje jezika i terminologije. Primarni izbor je gordicaleksa/YugoGPT, koji se moÅ¾e pokrenuti direktno putem Ollama komande: ollama run gordicaleksa/YugoGPT.4 Ovaj model je zasnovan na Mistral 7B, Å¡to garantuje kompatibilnost sa ostalim odabranim alatima, dok mu BCS pre-trening daje superiornu polaznu osnovu.
Model za Embedinge (Embedding Model): Za pretvaranje tekstualnih segmenata u vektorske reprezentacije (embedinge), koristiÄ‡e se visokokvalitetan, open-source model iz sentence-transformers biblioteke, kao Å¡to je sentence-transformers/all-MiniLM-L6-v2 ili sliÄan model optimizovan za viÅ¡ejeziÄne primene. Ovaj model Ä‡e se takoÄ‘e izvrÅ¡avati lokalno.

3.2. Implementacija Vektorske Baze Podataka sa Qdrant-om

Postavljanje (Setup): Qdrant Ä‡e biti pokrenut lokalno koristeÄ‡i zvaniÄnu Docker sliku.42 Ovo je jednostavan i pouzdan naÄin za postavljanje produkciono spremne vektorske baze podataka. Pokretanje se vrÅ¡i komandom koja mapira neophodne portove i montira lokalni volumen za perzistentnost podataka.
Kreiranje Kolekcije: KoristeÄ‡i qdrant-client Python biblioteku, napisaÄ‡e se skripta za kreiranje kolekcije.44 KljuÄni koraci su:
Definisanje imena kolekcije (npr. pravni_predmeti).
Definisanje vektorskih parametara: size (dimenzionalnost) mora odgovarati izlaznoj dimenziji odabranog embedding modela, a distance metrika (npr. Cosine ili Dot) treba da bude usklaÄ‘ena sa naÄinom na koji je embedding model treniran.
Kreiranje Indeksa za Metapodatke (Payload Indexes): Ovo je najvaÅ¾niji korak specifiÄan za ovaj projekat. Za svaki ekstrahovani metapodatak (case_id, judge, decision_date, court, itd.), kreiraÄ‡e se odgovarajuÄ‡i indeks unutar Qdrant-a.43
Ovaj poslednji korak je od fundamentalnog znaÄaja. Dok standardni RAG sistemi vrÅ¡e iskljuÄivo semantiÄku pretragu nad celim korpusom, pravna praksa zahteva daleko preciznije upite. Na primer, upit "PrikaÅ¾i mi sliÄne sluÄajeve pred Vrhovnim sudom u vezi sa naknadom Å¡tete posle 2010. godine" sadrÅ¾i i semantiÄki deo ("naknada Å¡tete") i striktne filtere ("Vrhovni sud", "posle 2010").
Qdrant-ova sposobnost da prvo izvrÅ¡i brzo filtriranje na osnovu indeksiranih metapodataka (court: "Vrhovni sud", date > 2010-01-01) drastiÄno suÅ¾ava prostor pretrage.8 Tek unutar tog znatno manjeg i relevantnijeg podskupa dokumenata, Qdrant vrÅ¡i semantiÄku (vektorsku) pretragu. Ovo pretvara sistem iz jednostavnog pretraÅ¾ivaÄa u moÄ‡an alat za pravno istraÅ¾ivanje. Implementacija u LangChain-u mora biti dizajnirana tako da
retriever prihvata ne samo tekstualni upit, veÄ‡ i strukturirane filtere, omoguÄ‡avajuÄ‡i hibridnu pretragu.46

3.3. Indeksiranje Korpusa

Skripta (index_corpus.py): Ova skripta Ä‡e izvrÅ¡iti masovni unos pripremljenih podataka u Qdrant.
UÄitava strukturirane JSON datoteke kreirane u Fazi 1.
Za svaki dokument, iterira kroz njegove tekstualne segmente (chunks).
Za svaki segment, koristi sentence-transformer model da generiÅ¡e vektorski embedding.
Poziva qdrant_client.upsert() metodu da unese "taÄku" (point) u kolekciju. Svaka taÄka se sastoji od jedinstvenog ID-a, generisanog vektora i "payload-a" koji sadrÅ¾i sam tekst segmenta i sve nasleÄ‘ene metapodatke od roditeljskog dokumenta.43
Ovaj proces Ä‡e se izvrÅ¡avati u serijama (batches) radi efikasnosti.

3.4. Orkestracija RAG-a pomoÄ‡u LangChain-a

LangChain Ä‡e se koristiti za povezivanje svih komponenti u funkcionalan cevovod za odgovaranje na pitanja.
Osnovne Komponente: KoristiÄ‡e se LangChain Expression Language (LCEL) za deklarativno i transparentno definisanje lanca.48
Lanac (The Chain):
Ulaz (Input): Pitanje korisnika.
Retriever: Objekat kreiran sa QdrantVectorStore.as_retriever().49 Ovaj retriever Ä‡e biti konfigurisan da prima i dinamiÄke filtere za metapodatke.
Å ablon Prompta (Prompt Template): PaÅ¾ljivo sastavljen prompt koji daje LLM-u instrukcije da se ponaÅ¡a kao ekspert srpskog prava. KljuÄne instrukcije su:
Odgovor mora biti zasnovan iskljuÄivo na pruÅ¾enom kontekstu (dokumentima koje je vratio retriever).
Zabranjeno je "haluciniranje" ili koriÅ¡Ä‡enje internog znanja modela.
Odgovor mora biti jasan, koncizan i na srpskom jeziku.
Kada je primenjivo, potrebno je citirati izvore (npr. navoÄ‘enjem broja predmeta iz metapodataka).
LLM: Instanca langchain_community.llms.Ollama klase, usmerena na lokalno pokrenut YugoGPT model.51
Izlazni Parser (Output Parser): Standardni StrOutputParser za dobijanje konaÄnog tekstualnog odgovora.
Finalna Skripta (rag_agent.py): Ova skripta Ä‡e sadrÅ¾ati kompletan, izvrÅ¡ni lanac. BiÄ‡e dizajnirana kao modularna funkcija ili klasa koja se moÅ¾e lako uvesti i koristiti unutar Streamlit aplikacije u sledeÄ‡oj fazi.51

IV. Faza 3: Interaktivna Konzola - Interfejs za 'Drvenog Advokata'

Ova faza se fokusira na izgradnju mosta izmeÄ‘u mentora-advokata i AI agenta. Interfejs mora biti jednostavan, intuitivan i, Å¡to je najvaÅ¾nije, efikasan u prikupljanju visokokvalitetnih povratnih informacija koje su neophodne za pokretanje petlje uÄenja. Streamlit je odabran kao tehnologija koja omoguÄ‡ava brzu izradu funkcionalnog i interaktivnog korisniÄkog interfejsa sa minimalnim naporom.

4.1. Izgradnja Streamlit Chat Interfejsa (app.py)

Osnovni Interfejs: Jezgro aplikacije Ä‡e biti chat interfejs, kreiran pomoÄ‡u st.chat_input za unos korisniÄkih poruka i st.chat_message za njihovo prikazivanje.15 Ovo stvara poznato okruÅ¾enje za konverzaciju.
Upravljanje Stanjem Sesije (Session State): Da bi se odrÅ¾ao kontinuitet razgovora, celokupna istorija interakcije (pitanja korisnika i odgovori agenta) biÄ‡e Äuvana u st.session_state.15
st.session_state je mehanizam koji Streamlit pruÅ¾a za Äuvanje varijabli izmeÄ‘u ponovnih izvrÅ¡avanja skripte, Å¡to se deÅ¡ava nakon svake interakcije korisnika. Istorija Ä‡e biti Äuvana kao lista reÄnika, gde svaki reÄnik predstavlja jednu poruku sa kljuÄevima kao Å¡to su role ("user" ili "assistant") i content (tekst poruke).
Prikaz Istorije: Prilikom svakog ponovnog pokretanja aplikacije, skripta Ä‡e prvo proÄ‡i kroz listu poruka u st.session_state.history i iscrtati sve prethodne poruke. Ovo osigurava da korisnik uvek vidi ceo tok trenutne konverzacije.

4.2. Implementacija Mehanizma za Povratne Informacije

Komponenta za Feedback: Za prikupljanje ocena odgovora, koristiÄ‡e se komponenta streamlit-feedback. Ova komponenta omoguÄ‡ava jednostavno dodavanje "palac gore/dole" (thumbs) ili drugih tipova ocena uz poruke.53
Integracija: Za svaki odgovor koji generiÅ¡e AI asistent, biÄ‡e prikazan i streamlit_feedback vidÅ¾et. KljuÄni deo implementacije je dodeljivanje jedinstvenog key atributa svakom vidÅ¾etu. Ovaj kljuÄ se obiÄno formira na osnovu indeksa poruke u istoriji razgovora (npr. f"feedback_{i}"), Å¡to omoguÄ‡ava Streamlit-u da pravilno upravlja stanjem svakog pojedinaÄnog vidÅ¾eta.15
Polje za Korekciju: Pored jednostavne ocene "palac gore/dole", Å¡to je signal niskog kvaliteta, najvaÅ¾niji element je polje za unos teksta gde mentor moÅ¾e da pruÅ¾i detaljnu ispravku. Ovo Ä‡e biti implementirano pomoÄ‡u st.text_area sa jasnim natpisom, na primer: "Ispravka ili bolji odgovor:". U ovo polje advokat Ä‡e unositi "zlatni standard" odgovora, ispravljajuÄ‡i logiku, stil ili ÄinjeniÄnu taÄnost odgovora agenta. Ovaj tekstualni unos je najvredniji podatak za buduÄ‡e fino podeÅ¡avanje modela.

4.3. Prikupljanje i SkladiÅ¡tenje Povratnih Informacija za Fino PodeÅ¡avanje

Callback Funkcija: Interakcija sa streamlit-feedback vidÅ¾etom i unos teksta u polje za ispravku biÄ‡e povezani sa funkcijom za Äuvanje podataka. on_change parametar streamlit-feedback komponente Ä‡e pozvati save_feedback_to_log funkciju.15 SliÄno, unos u
st.text_area Ä‡e biti saÄuvan.
Struktura Podataka: Kada se povratna informacija zabeleÅ¾i, funkcija Ä‡e prikupiti kompletan snimak interakcije. Nije dovoljno saÄuvati samo loÅ¡ i dobar odgovor. Za efikasno fino podeÅ¡avanje, modelu je potreban ceo kontekst. Podaci koji se Äuvaju ukljuÄuju:
Originalni upit korisnika koji je doveo do odgovora.
Celokupnu istoriju razgovora do tog trenutka, radi konteksta.
Odgovor agenta koji se koriguje.
Ocenu (npr. "thumb_down").
Tekstualnu ispravku koju je uneo ekspert.
Perzistencija: Prikupljeni podaci Ä‡e biti serijalizovani u JSON format i dodati kao novi red u datoteku feedback_log.jsonl. Format JSONL (JSON Lines) je idealan za logovanje jer je svaka linija samostalni, validni JSON objekat. Ovo omoguÄ‡ava lako i efikasno dodavanje novih zapisa (append) i kasnije Äitanje, bez potrebe za parsiranjem cele datoteke.54
Tabela 1: Struktura Datoteke feedback_log.jsonl
Ova tabela definiÅ¡e Å¡emu podataka koji se prikupljaju. Konzistentna i bogata struktura je preduslov za automatizovanu obradu u Fazi 4. Svaki red u ovoj datoteci predstavlja jedan primer za potencijalni trening.
KljuÄ (Key)
Tip Podatka
Opis
timestamp
String (ISO 8601)
TaÄno vreme kada je povratna informacija zabeleÅ¾ena.
session_id
String
Jedinstveni identifikator za celu konverzacionu sesiju.
user_query
String
Konkretan upit korisnika koji je generisao odgovor koji se ocenjuje.
conversation_history
Lista ReÄnika
Lista svih prethodnih poruka ({"role":..., "content":...}) u sesiji.
agent_response
String
Kompletan tekst odgovora agenta koji se koriguje.
feedback_score
String
Ocena data putem streamlit-feedback komponente (npr. "ğŸ‘" ili "ğŸ‘").
expert_correction
String
Tekstualna ispravka uneta od strane advokata. Ovo je ciljni izlaz za fino podeÅ¡avanje.
retrieved_context
Lista Stringova
(Opciono, ali preporuÄljivo) Lista segmenata teksta koje je RAG sistem preuzeo i koristio za generisanje agent_response.

UkljuÄivanje retrieved_context je veoma korisno jer omoguÄ‡ava analizu da li je problem bio u loÅ¡em preuzimanju dokumenata ili u loÅ¡em rezonovanju LLM-a na osnovu dobrih dokumenata.

V. Faza 4: Petlja UÄenja - Implementacija Samokorekcije i UsavrÅ¡avanja

Ovo je najnaprednija faza projekta, gde 'Drveni advokat' prelazi sa nivoa alata koji poseduje znanje na nivo pripravnika koji uÄi. U ovoj fazi se automatizuje proces transformacije ekspertske povratne informacije u merljivo poboljÅ¡anje performansi modela. Ovaj ciklus uÄenja je ono Å¡to projektu daje dugoroÄnu vrednost i omoguÄ‡ava mu da zaista postane digitalno nasleÄ‘e.

5.1. Kreiranje Seta Podataka za Fino PodeÅ¡avanje iz Povratnih Informacija

Skripta (prepare_finetune_data.py): Svrha ove skripte je da sirove logove povratnih informacija pretvori u Äist, strukturiran set podataka pogodan za obuku.
UÄitavanje Logova: Skripta Ä‡e Äitati feedback_log.jsonl datoteku, red po red.
Filtriranje: Proces Ä‡e se fokusirati na primere koji predstavljaju jasne signale za uÄenje. To znaÄi filtriranje zapisa koji imaju negativnu ocenu (npr. "thumb_down") i gde postoji popunjen expert_correction tekst. Ovi zapisi predstavljaju parove "loÅ¡ odgovor -> dobar odgovor".
Formatiranje: Svaki filtrirani zapis Ä‡e biti transformisan u format pogodan za SFTTrainer (Supervised Fine-tuning Trainer) iz trl biblioteke. "Alpaca" stil formatiranja je dobro uspostavljen standard koji se sastoji od instrukcije, opcionog ulaza i izlaza.56 Za ovaj projekat, format moÅ¾e izgledati ovako:
JSON
{
  "instruction": "Na osnovu sledeÄ‡eg konteksta iz relevantnih predmeta, odgovori na pitanje korisnika. Kontekst: [tekst preuzetih dokumenata]. Pitanje: [originalni upit korisnika]",
  "output": "[tekstualna ispravka od strane eksperta]"
}

Alternativno, i Äesto robusnije, ceo primer se moÅ¾e formatirati kao jedan tekstualni niz koji SFTTrainer moÅ¾e direktno da koristi, kombinujuÄ‡i instrukciju i odgovor u jedinstveni format koji model uÄi da prati.58 Na primer:

<s> {instrukcija} {oÄekivani_odgovor} </s>
Izlaz: Skripta Ä‡e generisati novu datoteku, finetuning_dataset.jsonl, koja sadrÅ¾i samo formatirane primere spremne za obuku.

5.2. Parametarski Efikasno Fino PodeÅ¡avanje (PEFT) sa LoRA

Koncept: Potpuno fino podeÅ¡avanje (full fine-tuning) modela od 7 milijardi parametara je izuzetno zahtevno u pogledu raÄunarskih resursa, posebno VRAM-a. LoRA (Low-Rank Adaptation) je PEFT tehnika koja reÅ¡ava ovaj problem. Umesto da menja sve teÅ¾ine modela, LoRA zamrzava originalne teÅ¾ine i dodaje male, "adapter" slojeve koji se jedini treniraju.60 Broj parametara koji se treniraju je drastiÄno manji (Äesto <1% od ukupnog broja), Å¡to znaÄajno smanjuje zahteve za memorijom i omoguÄ‡ava fino podeÅ¡avanje na potroÅ¡aÄkom hardveru (10GB VRAM je dovoljno za LoRA na 7B modelu, posebno uz kvantizaciju).62
Skripta (run_finetuning.py):
UÄitavanje Osnovnog Modela i Tokenizatora: UÄitati YugoGPT model koristeÄ‡i transformers biblioteku. KljuÄno je uÄitati model sa 4-bitnom kvantizacijom (BitsAndBytesConfig) kako bi se maksimalno smanjila potroÅ¡nja VRAM-a.63
UÄitavanje Seta Podataka: UÄitati finetuning_dataset.jsonl kreiran u prethodnom koraku.
Konfiguracija LoRA: Definisati LoraConfig objekat iz peft biblioteke. Ovde se specificiraju kljuÄni hiperparametri, kao Å¡to su r (rang), lora_alpha, i target_modules (slojevi modela na koje Ä‡e se primeniti LoRA, obiÄno slojevi paÅ¾nje kao Å¡to su q_proj, v_proj).62
Instanciranje Trenera: Kreirati instancu SFTTrainer iz trl biblioteke, prosleÄ‘ujuÄ‡i joj kvantizovani model, set podataka, tokenizator i LoRA konfiguraciju.64
Obuka: Pozvati trainer.train(). Ovaj proces Ä‡e trajati odreÄ‘eno vreme (zavisno od veliÄine seta podataka), ali Ä‡e trenirati samo male LoRA adaptere.
ÄŒuvanje Adaptera: Nakon zavrÅ¡etka obuke, saÄuvati teÅ¾ine adaptera pomoÄ‡u trainer.model.save_pretrained(). Rezultat neÄ‡e biti novi model od 7B, veÄ‡ mala datoteka (nekoliko desetina do stotina megabajta) koja sadrÅ¾i samo teÅ¾ine adaptera.

5.3. Automatizacija Ciklusa AÅ¾uriranja Modela

Strategija: Nije potrebno ponovo trenirati model od nule svaki put. Fino podeÅ¡avanje se moÅ¾e pokretati periodiÄno (npr. jednom dnevno ili nedeljno), samo ako su u feedback_log.jsonl dodate nove korekcije.
DinamiÄko UÄitavanje: Glavna skripta agenta (rag_agent.py) Ä‡e biti modifikovana. Prilikom pokretanja, ona Ä‡e prvo uÄitati osnovni, kvantizovani YugoGPT model. Zatim Ä‡e proveriti da li postoji saÄuvan LoRA adapter u predviÄ‘enom direktorijumu. Ako adapter postoji, koristiÄ‡e PeftModel.from_pretrained() da dinamiÄki spoji teÅ¾ine adaptera sa osnovnim modelom u memoriji. Ovo osigurava da agent uvek radi sa najnovijom verzijom znanja i rezonovanja koje je nauÄio iz korekcija, bez potrebe za permanentnim spajanjem modela.

5.4. Napredna Samokorekcija: Prompting za Internu Kritiku

Pored eksterne petlje uÄenja voÄ‘ene mentorskim ispravkama, moguÄ‡e je implementirati i internu petlju gde agent sam kritikuje svoje odgovore pre nego Å¡to ih prikaÅ¾e korisniku. Ovo se postiÅ¾e kroz napredne tehnike promptinga.
Implementacija Self-Refine: Lanac u LangChain-u se moÅ¾e proÅ¡iriti da ukljuÄi korake samorefleksije.65
Inicijalna Generacija: Agent generiÅ¡e odgovor na osnovu preuzetog konteksta, kao i do sada.
Prompt za Samokritiku: Pre prikazivanja odgovora, agent interno poziva LLM ponovo, sa novim promptom koji sadrÅ¾i originalno pitanje i generisani odgovor. Primer prompta: "Ovo je pitanje korisnika i moj predloÅ¾eni odgovor. KritiÄki preispitaj odgovor. Da li je odgovor direktno povezan sa pitanjem? Da li su sve tvrdnje potkrepljene u priloÅ¾enom kontekstu? Da li postoji logiÄka nedoslednost? Navedi potencijalne nedostatke."
Prompt za Finalno UsavrÅ¡avanje: Agent uzima originalno pitanje, inicijalni odgovor i sopstvenu kritiku i poziva LLM poslednji put sa promptom: "Na osnovu sledeÄ‡ih kritika, usavrÅ¡i prvobitni odgovor kako bi bio precizniji i pouzdaniji."
Sinergija Dve Petlje UÄenja: Ove dve petljeâ€”eksterna (mentor) i interna (samokritika)â€”nisu meÄ‘usobno iskljuÄive, veÄ‡ su sinergijske.
Eksterna petlja, voÄ‘ena ispravkama advokata, uÄi model fundamentalnim obrascima pravnog rezonovanja. Fino podeÅ¡avanje sa LoRA ne samo da uÄi model taÄnim odgovorima, veÄ‡ ga uÄi stilu i naÄinu razmiÅ¡ljanja.
Interna petlja (Self-Refine) daje modelu mehanizam da primeni to nauÄeno rezonovanje u realnom vremenu, na novim, neviÄ‘enim problemima.
Model koji je kroz fino podeÅ¡avanje nauÄio da rezonuje sliÄnije ekspertu biÄ‡e takoÄ‘e bolji u prepoznavanju nedostataka u sopstvenom rezonovanju tokom koraka samokritike. Ovo stvara moÄ‡an pozitivan ciklus: mentorske ispravke poboljÅ¡avaju osnovno rezonovanje modela, Å¡to zauzvrat poboljÅ¡ava njegovu sposobnost samokorekcije, Å¡to dovodi do boljih inicijalnih odgovora koji zahtevaju manje ispravki u buduÄ‡nosti. Ova sinergija je kljuÄ za skaliranje ekspertize agenta izvan specifiÄnih primera koji su ispravljeni.

VI. StrateÅ¡ke Preporuke i Mapa Puta Projekta

Ovaj zavrÅ¡ni odeljak pruÅ¾a jasan, fazni plan za razvoj i preporuke za upravljanje projektom, osiguravajuÄ‡i da se kompleksnost reÅ¡ava na strukturiran i upravljiv naÄin.

6.1. Fazna Mapa Puta za Razvoj

Projekat treba razvijati u diskretnim, logiÄkim fazama. Svaka faza treba da rezultira funkcionalnom komponentom, omoguÄ‡avajuÄ‡i iterativni napredak i testiranje.
Faza 1 - Temelj Podataka (Data Foundation): Apsolutni prioritet je skripta za konverziju .doc formata i ekstrakciju podataka. Ova faza je zavrÅ¡ena tek kada postoji Äist, strukturiran JSONL set podataka koji predstavlja celokupan korpus od 200 GB. Pre nego Å¡to je ovaj korak 100% zavrÅ¡en i verifikovan, ne treba prelaziti na sledeÄ‡e faze.
Faza 2 - Jezgro RAG Agenta (Core RAG Agent): Izgraditi osnovni RAG agent koristeÄ‡i Ollama, Qdrant i LangChain. Cilj ove faze je funkcionalan sistem za pitanja i odgovore koji se u potpunosti oslanja na pretragu (retrieval). U ovoj fazi, agent joÅ¡ uvek ne uÄi.
Faza 3 - Interaktivni Interfejs (Interactive Interface): Razviti Streamlit korisniÄki interfejs i integrisati mehanizam za povratne informacije. Povezati ga sa agentom iz Faze 2. Od ovog trenutka, moÅ¾e se poÄeti sa koriÅ¡Ä‡enjem sistema i prikupljanjem ispravki u feedback_log.jsonl datoteku.
Faza 4 - Petlja UÄenja (The Learning Loop): Nakon Å¡to se prikupi dovoljna koliÄina podataka o povratnim informacijama (npr. 50-100 kvalitetnih ispravki), implementirati skripte za pripremu podataka i fino podeÅ¡avanje (prepare_finetune_data.py i run_finetuning.py). Implementirati mehanizam za dinamiÄko uÄitavanje LoRA adaptera.
Faza 5 - Napredno UsavrÅ¡avanje (Advanced Refinement): Kada je petlja uÄenja uspostavljena i funkcionalna, implementirati interne tehnike samokritike (npr. Self-Refine) unutar LangChain lanca kako bi se dodatno poboljÅ¡ala pouzdanost i taÄnost odgovora u realnom vremenu.

6.2. Upravljanje Projektom za Individualnog Programera

S obzirom na to da je ovo projekat koji vodi jedna osoba, kljuÄno je odrÅ¾ati ga organizovanim i upravljivim.
Jednostavnost je KljuÄ: Zahtev da se izbegne "previÅ¡e.py fajlova" je mudar. Kod treba organizovati u logiÄke celine koje odgovaraju fazama razvoja:
convert_corpus.py: Za Fazu 1 (konverzija).
extract_and_structure.py: Za Fazu 1 (ekstrakcija).
index_corpus.py: Za Fazu 2 (indeksiranje u Qdrant).
rag_agent.py: Definicija LangChain lanca i logike agenta.
app.py: Glavna Streamlit aplikacija.
finetuning.py: Skripta koja objedinjuje pripremu podataka i pokretanje LoRA treninga.
config.py: Centralno mesto za sve konfiguracione parametre (putanje, imena modela, URL-ovi).
Kontrola Verzija (Version Control): Koristiti Git od prvog dana. Ovo je neprocenjivo za praÄ‡enje promena, posebno u promptovima, konfiguracijama modela i logici lanca. OmoguÄ‡ava sigurno eksperimentisanje sa moguÄ‡noÅ¡Ä‡u povratka na prethodnu stabilnu verziju.
Iterativni Pristup: Striktno se pridrÅ¾avati fazne mape puta. Ne pokuÅ¡avati izgraditi sve odjednom. Svaka faza treba da bude mini-projekat sa jasnim ciljem. Ovaj pristup spreÄava preoptereÄ‡enje, omoguÄ‡ava redovno testiranje i pruÅ¾a oseÄ‡aj konstantnog napretka, Å¡to je kljuÄno za odrÅ¾avanje motivacije na dugoroÄnom, solo projektu. Po zavrÅ¡etku svake faze, treba napraviti rezervnu kopiju (backup) celokupnog radnog direktorijuma i generisanih podataka.